<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bash on Windows on suspiciously datalicious</title>
    <link>https://triamus.github.io/tags/bash-on-windows/</link>
    <description>Recent content in Bash on Windows on suspiciously datalicious</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Alexander Wagner</copyright>
    <lastBuildDate>Sat, 07 Oct 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="/tags/bash-on-windows/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Install Docker on Windows</title>
      <link>https://triamus.github.io/post/install-docker-on-windows/</link>
      <pubDate>Sat, 07 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://triamus.github.io/post/install-docker-on-windows/</guid>
      <description>&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#overview&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;1&lt;/span&gt; Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#system-requirements&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2&lt;/span&gt; System requirements&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#install-docker&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3&lt;/span&gt; Install Docker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#run-docker&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4&lt;/span&gt; Run Docker&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#cmd&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.1&lt;/span&gt; CMD&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#powershell&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.2&lt;/span&gt; Powershell&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#bash-on-windows&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4.3&lt;/span&gt; Bash on Windows&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;1&lt;/span&gt; Overview&lt;/h1&gt;
&lt;p&gt;This is a quick tutorial how to install Docker on Windows and use it via CMD or Bash on Windows (Linux subsystem for Windows - WSL). It is assumed that the reader has basic knowledge of the Windows command line (CMD) and, if Bash should be used, a basic familiarity with Bash on Ubuntu on Windows. We will demonstrate a basic example to run a docker image.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;system-requirements&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;2&lt;/span&gt; System requirements&lt;/h1&gt;
&lt;p&gt;For detailed system requirements, see &lt;a href=&#34;https://docs.docker.com/docker-for-windows/install/#what-to-know-before-you-install&#34;&gt;What to know before you install&lt;/a&gt; but main requirements are&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hyper-V running/enabled (note that this means that VirtualBox VM images won’t run anymore and there may be other implications for high-precision applications, see details at &lt;a href=&#34;https://docs.microsoft.com/en-us/virtualization/hyper-v-on-windows/about/&#34;&gt;Introduction to Hyper-V on Windows 10&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;64bit Windows 10 Pro/Education/Enterprise (there are people claiming Docker runs on Windows 10 Home but we found this not to be true when trying ourselves as Hyper-V seems only available for Pro, Education and Enterprise versions - 1511 November update, Build 10586 or later), see also official Microsoft page on Hyper-V system requirements at &lt;a href=&#34;https://docs.microsoft.com/en-us/virtualization/hyper-v-on-windows/quick-start/enable-hyper-v&#34;&gt;Install Hyper-V on Windows 10&lt;/a&gt;. Windows &amp;gt;= 8 may work as well but we haven’t tested it.&lt;/li&gt;
&lt;li&gt;Virtualization must be enabled&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;install-docker&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;3&lt;/span&gt; Install Docker&lt;/h1&gt;
&lt;p&gt;The installation is best performed by using officially provided binary installer from &lt;a href=&#34;https://docs.docker.com/docker-for-windows/install/&#34;&gt;Docker webpage&lt;/a&gt;. We recommend the stable version unless you need latest changes from development version. Once the installation is through (and PC restarted) Docker should be automatically running indicated by its icon showing in the task bar.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://triamus.github.io/post/img/2017-10-07-install-docker-on-windows/windows_docker_is_running.png&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;In case it is not running for you, one reason might be that the automatic enabling of Hyper-V during the Docker installation did not work. Check the official Microsoft page on Hyper-V at &lt;a href=&#34;https://docs.microsoft.com/en-us/virtualization/hyper-v-on-windows/quick-start/enable-hyper-v&#34;&gt;Install Hyper-V on Windows 10&lt;/a&gt; to see a couple of ways to enable it. Also note that Hyper-V activation and virtualization activation are not the same thing so make sure virtualization is enabled in BIOS, too (usually the case if you used virtual machines before, e.g. via VirtualBox). See how to enable it at &lt;a href=&#34;https://blogs.technet.microsoft.com/canitpro/2015/09/08/step-by-step-enabling-hyper-v-for-use-on-windows-10/&#34;&gt;Step-By-Step: Enabling Hyper-V for use on Windows 10&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://triamus.github.io/post/img/2017-10-07-install-docker-on-windows/windows_docker_activate_hyper-v.PNG&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;You can also check Hyper-V status on a detailed level via &lt;code&gt;Powershell&lt;/code&gt; using below (run as admin)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Get-WindowsOptionalFeature -Online -FeatureName *hyper*&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;run-docker&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;4&lt;/span&gt; Run Docker&lt;/h1&gt;
&lt;p&gt;Docker can be run in a few ways, we show it via CMD, Powershell and Bash on Windows. In general, CMD and Powershell usage should be fairly similar but you may require some additional wrangling for Bash. If you used the official Windows binary installer from the Docker webpage, the relevant path/environment variables should already be set and you can start using it right away. As opposed to running Docker on Linux, Windows should not require running the terminal as admin.&lt;/p&gt;
&lt;div id=&#34;cmd&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.1&lt;/span&gt; CMD&lt;/h2&gt;
&lt;p&gt;Check if Docker works by testing below examples. Note that you require an internet connection in case you have never used below Docker images before (e.g. hello-world) as Docker will automatically download/pull those.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker --version
docker run hello-world&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://triamus.github.io/post/img/2017-10-07-install-docker-on-windows/windows_cmd_docker_version.PNG&#34; /&gt;

&lt;/div&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://triamus.github.io/post/img/2017-10-07-install-docker-on-windows/windows_cmd_docker_hello_world.PNG&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;Finally you can run a more demanding example by running a Linux Ubuntu Bash terminal (this may take some time depending on your bandwidth as the complete Ubuntu image is pulled). Note that you are made &lt;code&gt;root&lt;/code&gt; user in the shell.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker run -it ubuntu bash&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://triamus.github.io/post/img/2017-10-07-install-docker-on-windows/windows_cmd_docker_run_it_ubuntu_bash.PNG&#34; /&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;powershell&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.2&lt;/span&gt; Powershell&lt;/h2&gt;
&lt;p&gt;As CMD, Powershell should work out of the box so we only show the hello-world example here again. Note that the image is not pulled again as we had just used it before in CMD.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker run hello-world&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://triamus.github.io/post/img/2017-10-07-install-docker-on-windows/windows_ps_docker_hello_world.PNG&#34; /&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;bash-on-windows&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;4.3&lt;/span&gt; Bash on Windows&lt;/h2&gt;
&lt;p&gt;In general, Bash on Windows should inherit the &lt;code&gt;PATH&lt;/code&gt; from Windows environment variables and thus work out of the box as well but there are a couple of things to note (&lt;strong&gt;note&lt;/strong&gt; special care when working with WSL config files as outlined in subsection &lt;a href=&#34;https://triamus.github.io/post/install-spark-on-windows/#A%20general%20note%20of%20caution%20for%20Bash%20on%20Windows&#34;&gt;A general note of caution for Bash on Windows&lt;/a&gt;).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Windows binary installer sets &lt;code&gt;PATH&lt;/code&gt; variable as &lt;code&gt;C:\Program Files\Docker\Docker\Resources\bin&lt;/code&gt; although it should actually be &lt;code&gt;C:\Program Files\Docker\Docker\resources\bin&lt;/code&gt;, i.e. lower case &lt;code&gt;r&lt;/code&gt; in &lt;code&gt;resources&lt;/code&gt;. This should generally not be an issue in case-insensitive Windows but may lead to issues in Linux (WSL) although we haven’t encountered any. Still you may want to adjust it.&lt;/li&gt;
&lt;li&gt;We found that you get the error &lt;code&gt;Unable to translate current working directory. Using C:\WINDOWS\system32&lt;/code&gt; when running Docker in WSL in some directories, e.g. home (~), but not when running it in others, e.g. in &lt;code&gt;/mnt/c/Program\ Files/Docker/Docker/resources/bin&lt;/code&gt;. This is apparently expected as some directories have no Windows equivalent, see this &lt;a href=&#34;https://github.com/Microsoft/BashOnWindows/issues/2011&#34;&gt;Github issue&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Docker on Windows comes as binary, i.e. &lt;code&gt;docker.exe&lt;/code&gt;. To avoid extra typing and confusion you probably want to set an alias e.g. in your &lt;code&gt;.bashrc&lt;/code&gt; file as so &lt;code&gt;alias docker=&amp;quot;docker.exe&amp;quot;&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In case you find Docker not working with an error message like &lt;code&gt;The program &amp;quot;docker&amp;quot; is currently not installed. You can install it by typing: sudo apt-get install docker&lt;/code&gt; it is probably caused by not having set the alias correctly or because Windows does not find Docker in the &lt;code&gt;PATH&lt;/code&gt;. You can try pointing Windows to the Docker install by including it in the &lt;code&gt;PATH&lt;/code&gt; via .bashrc as so &lt;code&gt;PATH=&amp;quot;$PATH:/mnt/c/Program\ Files/Docker/Docker/resources/bin&amp;quot;&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Finally, we run the same examples as with CMD (we spare you running an Ubuntu image from an Ubuntu system as WSL although it would be possible of course).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker --version
docker run hello-world&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://triamus.github.io/post/img/2017-10-07-install-docker-on-windows/windows_bash_docker_version.PNG&#34; /&gt;

&lt;/div&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://triamus.github.io/post/img/2017-10-07-install-docker-on-windows/windows_bash_docker_hello_world.PNG&#34; /&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Install ApacheSpark on Windows</title>
      <link>https://triamus.github.io/post/2017-09-22-install-spark-on-windows/</link>
      <pubDate>Fri, 22 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://triamus.github.io/post/2017-09-22-install-spark-on-windows/</guid>
      <description>

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#overview&#34;&gt;Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#system-requirements&#34;&gt;System requirements&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#a-general-note-of caution-for-bash-on-windows&#34;&gt;A general note of caution for Bash on Windows&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#install-java&#34;&gt;Install Java&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#install-python&#34;&gt;Install Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#example-output-for-system&#34;&gt;Example output for system&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#install-scala&#34;&gt;Install Scala&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#setting-environment-variables&#34;&gt;Setting environment variables&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#download/clone-windows-utilities-for-corresponding-hadoop-version&#34;&gt;Download/clone windows utilities for corresponding Hadoop version&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#make-/tmp/hive-writable&#34;&gt;Make /tmp/hive writable&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#run-spark-shell&#34;&gt;Run Spark shell&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#run-pyspark&#34;&gt;Run PySpark&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;

&lt;p&gt;This is a quick tutorial how to install ApacheSpark on Windows via the pre-built on Apache Hadoop. It is assumed that the reader has basic knowledge of the Windows command line (CMD) and, if Bash should be used, a basic familiarity with Bash on Ubuntu on Windows (part of Linux Subsystem on Windows). We will demonstrate a basic example how to use Scala and Python (via PySpark) from the command line.&lt;/p&gt;

&lt;h2 id=&#34;system-requirements&#34;&gt;System requirements&lt;/h2&gt;

&lt;p&gt;We show how to install Spark on Windows 10 (see exact system info below) but generally it should also work on Windows 7. You will require (we give install instructions below)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Windows 10 (prior versions, i.e. Windows &amp;gt;= 7, may work but not tested)&lt;/li&gt;
&lt;li&gt;Bash on Ubuntu on Windows (Linux subsystem on Windows) in case Bash should be used (not required per se)&lt;/li&gt;
&lt;li&gt;Java runtime environment (JRE) or Java Development Kit (JDK) version &amp;gt;= 8&lt;/li&gt;
&lt;li&gt;Scala&lt;/li&gt;
&lt;li&gt;Python (in case you want to use PySpark)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;a-general-note-of-caution-for-bash-on-windows&#34;&gt;A general note of caution for Bash on Windows&lt;/h3&gt;

&lt;p&gt;If you plan to set up Bash on Windows to work with Spark etc. you will eventually edit configuration files of the Linux on Windows subsystem. It is &lt;strong&gt;very important&lt;/strong&gt; that you do not use any Windows apps/tools to perform any operation on Linux files as these files may get corrupted. This includes using any Windows editor to edit Linux files (e.g. Notepad/++). For more details, see &lt;a href=&#34;https://blogs.msdn.microsoft.com/commandline/2016/11/17/do-not-change-linux-files-using-windows-apps-and-tools/&#34; target=&#34;_blank&#34;&gt;Do not change Linux files using Windows apps and tools&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;install-java&#34;&gt;Install Java&lt;/h3&gt;

&lt;p&gt;Binary installers for Java can be downloaded from &lt;a href=&#34;http://www.oracle.com/technetwork/java/javase/downloads/index.html&#34; target=&#34;_blank&#34;&gt;Oracle Java SE&lt;/a&gt;. To run Spark, you only require a Java runtime environment (JRE) but you may also download the Java development kit (JDK) which includes the JRE. Note that the path to the JRE may be different when using a JDK.&lt;/p&gt;

&lt;p&gt;You can check which version of Java you are running on the CMD via&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;java -version
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In case you like to use Bash, you will need to install Java on the Linux subsystem for Windows separately as it is a distinct OS. You can do so by following instructions from @rs6g10 on &lt;a href=&#34;https://github.com/Microsoft/BashOnWindows/issues/49&#34; target=&#34;_blank&#34;&gt;Microsoft/BashOnWindows/Unable to install Java JDK or Runtime #49&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;install-python&#34;&gt;Install Python&lt;/h3&gt;

&lt;p&gt;If you like to use the Spark Python API via PySpark, you will need to install Python. A frequently recommended distribution is often that of &lt;a href=&#34;https://www.anaconda.com/download/&#34; target=&#34;_blank&#34;&gt;Anaconda&lt;/a&gt; as it ships with a lot of useful libraries and has binary installers for Windows. Note that Bash on Windows already comes with Python 2.7 pre-installed so in case you like to work with Python3, you will have to install it using standard Bash workflow.&lt;/p&gt;

&lt;h3 id=&#34;example-output-for-system&#34;&gt;Example output for system&lt;/h3&gt;

&lt;p&gt;We show how our system is set up (your&amp;rsquo;s will probably vary). Type below commands in CMD (in succession)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;systeminfo | findstr /B /C:&amp;quot;OS Name&amp;quot; /C:&amp;quot;OS Version&amp;quot;
java -version
python --version
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://triamus.github.io/post/img/2017-09-22-install-spark-on-windows/cmd_system_and_version_info.PNG&#34; alt=&#34;CMD System Info&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We can do the same for Bash (note the default version of Python)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://triamus.github.io/post/img/2017-09-22-install-spark-on-windows/bash_system_and_version_info.PNG&#34; alt=&#34;Bash System Info&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;install-scala&#34;&gt;Install Scala&lt;/h2&gt;

&lt;p&gt;Generally, you can find Scala downloads &lt;a href=&#34;https://scala-lang.org/download/&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;. Find the Windows installer (in our case clicking on scala-2.12.3.msi under section Archive) downloads &lt;a href=&#34;https://downloads.lightbend.com/scala/2.12.3/scala-2.12.3.msi&#34; target=&#34;_blank&#34;&gt;this&lt;/a&gt;. Follow installation wizard.&lt;/p&gt;

&lt;p&gt;Once the installation is finished, open a new CMD and type&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;scala
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Your output should look like this&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://triamus.github.io/post/img/2017-09-22-install-spark-on-windows/cmd_scala_check_after_install.PNG&#34; alt=&#34;CMD Scala Check&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;install-spark&#34;&gt;Install Spark&lt;/h2&gt;

&lt;p&gt;Find the latest stable version of Spark on &lt;a href=&#34;http://spark.apache.org/downloads.html&#34; target=&#34;_blank&#34;&gt;Apache Spark Downloads&lt;/a&gt; and use pre-built on Hadoop and direct download.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://triamus.github.io/post/img/2017-09-22-install-spark-on-windows/download_spark.PNG&#34; alt=&#34;Spark Download Page&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Copy/save the .tgz file to/at the location where you like Spark to reside and extract it from some Linux shell (e.g. Bash, Cygwin) via below command (your file name may vary). Alternatively, you can use some extraction software such as 7zip.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# in case tar program is not installed, install e.g. via sudo apt-get install tar
tar xzfv spark-2.2.0-bin-hadoop2.7.tgz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://triamus.github.io/post/img/2017-09-22-install-spark-on-windows/bash_extract_spark_tgz.PNG&#34; alt=&#34;Bash extract Spark&#34; /&gt;&lt;/p&gt;

&lt;p&gt;After some time, your Spark install (extraction) should be done and a couple of folders being created at your chosen location.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://triamus.github.io/post/img/2017-09-22-install-spark-on-windows/spark_directory.png&#34; alt=&#34;Spark Directory&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;setting-environment-variables&#34;&gt;Setting environment variables&lt;/h2&gt;

&lt;p&gt;In order to make the system aware of all programs, we will be setting some environment variables. This can be done by simply using Windows search function in start menu and typing something like &lt;code&gt;environment variables&lt;/code&gt; and clicking the program &lt;code&gt;Edit the system environment variables&lt;/code&gt;. We will set the following variables (your location may vary)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;JAVA_HOME: C:\Program Files\Java\jre1.8.0_144&lt;/li&gt;
&lt;li&gt;SPARK_HOME: D:\spark\spark-2.2.0-bin-hadoop2.7&lt;/li&gt;
&lt;li&gt;HADOOP_HOME: D:\spark\spark-2.2.0-bin-hadoop2.7\bin&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Moreover, we will expand the system path with&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;C:\Program Files\Java\jre1.8.0_144\bin&lt;/li&gt;
&lt;li&gt;D:\spark\spark-2.2.0-bin-hadoop2.7\bin&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Note that the system environment variables are not necessarily shared with the Linux subsystem for Windows (although PATH seems to be shared). Any environment variable would thus have to be set in respective Linux configuration file.&lt;/p&gt;

&lt;p&gt;Your Windows environment variables may look something like this now&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://triamus.github.io/post/img/2017-09-22-install-spark-on-windows/windows_environment_variables.PNG&#34; alt=&#34;Windows Environment Variables&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;download-clone-windows-utilities-for-corresponding-hadoop-version&#34;&gt;Download/clone windows utilities for corresponding Hadoop version&lt;/h2&gt;

&lt;p&gt;Go to &lt;a href=&#34;https://github.com/steveloughran/winutils&#34; target=&#34;_blank&#34;&gt;Github/steveloughran/winutils&lt;/a&gt; and clone/copy the Windows utilities for your Hadoop version to your local Hadoop directory. Copy \winutils-master\winutils-master\hadoop-2.7.1\bin and paste into your Spark install. For us this would be D:\spark\spark-2.2.0-bin-hadoop2.7\bin.&lt;/p&gt;

&lt;h2 id=&#34;make-tmp-hive-writable&#34;&gt;Make /tmp/hive writable&lt;/h2&gt;

&lt;p&gt;To avoid a common error (see e.g. &lt;a href=&#34;https://stackoverflow.com/questions/34196302/the-root-scratch-dir-tmp-hive-on-hdfs-should-be-writable-current-permissions&#34; target=&#34;_blank&#34;&gt;The root scratch dir: /tmp/hive on HDFS should be writable. Current permissions are: rw-rw-rw- (on Windows)&lt;/a&gt; or  &lt;a href=&#34;https://hernandezpaul.wordpress.com/2016/01/24/apache-spark-installation-on-windows-10/&#34; target=&#34;_blank&#34;&gt;Apache Spark installation on Windows 10&lt;/a&gt; open CMD as administrator and run below against your Spark directory where Winutils should reside (so in our case in D:\spark\spark-2.2.0-bin-hadoop2.7\bin\bin)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;D:\&amp;gt;spark\spark-2.2.0-bin-hadoop2.7\bin\bin\winutils.exe chmod 777 \tmp\hive
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;run-spark-shell&#34;&gt;Run Spark shell&lt;/h2&gt;

&lt;p&gt;Finally, we can test our Spark installation by running the shell&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;spark-shell
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Your output should look something like below&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://triamus.github.io/post/img/2017-09-22-install-spark-on-windows/cmd_spark-shell.PNG&#34; alt=&#34;CMD Initial Spark Shell&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We execute a minimal example from &lt;a href=&#34;http://spark.apache.org/docs/latest/quick-start.html&#34; target=&#34;_blank&#34;&gt;Apache Spark Quick Start&lt;/a&gt; (note that the README file is located one directory up) to test basic functionality.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val textFile = spark.read.textFile(&amp;quot;../README.md&amp;quot;)
textFile.count() // Number of items in this Dataset
textFile.first() // First item in this Dataset
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://triamus.github.io/post/img/2017-09-22-install-spark-on-windows/cmd_scala_initial_test.PNG&#34; alt=&#34;CMD Scala Initial Test&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Since the Linux subsystem for Windows inherits the Path variables from Windows, we can run the same without further adjustments on Bash on Ubuntu on Windows&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://triamus.github.io/post/img/2017-09-22-install-spark-on-windows/bash_spark-shell.PNG&#34; alt=&#34;Bash Spark Shell&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;run-pyspark&#34;&gt;Run PySpark&lt;/h2&gt;

&lt;p&gt;Assuming you also want to use Python with Spark via &lt;a href=&#34;http://spark.apache.org/docs/2.1.0/api/python/pyspark.html&#34; target=&#34;_blank&#34;&gt;PySpark&lt;/a&gt; and have followed above setup instructions, you can open a new CMD and type below to test if PySpark works&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pyspark
# we show it with bin/pyspark but both will work if your environment variables are properly set
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Again, we execute a minimal example from &lt;a href=&#34;https://spark.apache.org/examples.html&#34; target=&#34;_blank&#34;&gt;Apache Spark Examples&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;text_file = sc.textFile(&amp;quot;README.md&amp;quot;)
counts = text_file.flatMap(lambda line: line.split(&amp;quot; &amp;quot;)) \
             .map(lambda word: (word, 1)) \
             .reduceByKey(lambda a, b: a + b)
print(counts)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://triamus.github.io/post/img/2017-09-22-install-spark-on-windows/cmd_pyspark_initial_test.PNG&#34; alt=&#34;CMD PySpark Initial Test&#34; /&gt;&lt;/p&gt;

&lt;p&gt;As before, the same command works in Bash but note the default Python version used&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://triamus.github.io/post/img/2017-09-22-install-spark-on-windows/bash_pyspark_initial_test.PNG&#34; alt=&#34;Bash PySpark Initial Test&#34; /&gt;&lt;/p&gt;

&lt;p&gt;In case you want to work with a different Python version, adjust respective Bash configuration file to export the environment variable (see line below). In our case, we use Python3.4 and define it in the &lt;code&gt;.profile&lt;/code&gt; file in the Bash home directory (&lt;code&gt;~&lt;/code&gt;).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;export PYSPARK_PYTHON=python3.4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://triamus.github.io/post/img/2017-09-22-install-spark-on-windows/bash_nano_profile.PNG&#34; alt=&#34;Bash nano profile&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The PySpark shell now runs Python 3.4 as default (this obviously needs to be adjusted in case you like to run a different Python version).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://triamus.github.io/post/img/2017-09-22-install-spark-on-windows/bash_pyspark_python3.PNG&#34; alt=&#34;bash_pyspark_python3&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
